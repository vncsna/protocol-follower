{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"scraper.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eqRzI--A5wPo"},"source":["### [Pensador](https://www.pensador.com/)"]},{"cell_type":"markdown","metadata":{"id":"e54vHATykM-x"},"source":["#### Libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rRnbAfYu70Bx","executionInfo":{"status":"ok","timestamp":1611003512169,"user_tz":240,"elapsed":3716,"user":{"displayName":"Vinicius Aguiar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIkJJn8xW1Jifzc3Yu1R42MS1Ter43iIMGz9IS=s64","userId":"17869074096365757693"}},"outputId":"2da41b69-d57c-4d6b-94f7-dfaa91e3bd6d"},"source":["!pip install -U python-dotenv"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: python-dotenv in /usr/local/lib/python3.6/dist-packages (0.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gMliwFC9kM-2","executionInfo":{"status":"ok","timestamp":1611003512170,"user_tz":240,"elapsed":3713,"user":{"displayName":"Vinicius Aguiar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIkJJn8xW1Jifzc3Yu1R42MS1Ter43iIMGz9IS=s64","userId":"17869074096365757693"}},"outputId":"f65c570c-f660-4038-ac77-41781104b435"},"source":["import os\n","import json\n","from pathlib import Path\n","from collections import OrderedDict\n","\n","import requests\n","import psycopg2\n","from bs4 import BeautifulSoup\n","from dotenv import load_dotenv\n","from IPython.display import clear_output"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n","  \"\"\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QnqIFOlckPNn","executionInfo":{"status":"ok","timestamp":1611003512171,"user_tz":240,"elapsed":3712,"user":{"displayName":"Vinicius Aguiar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIkJJn8xW1Jifzc3Yu1R42MS1Ter43iIMGz9IS=s64","userId":"17869074096365757693"}},"outputId":"c34621a5-7529-481c-9e56-2eb694fe41a2"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')\r\n","%cd '/content/drive/My Drive/github/sir-protocol-bot/scraper'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/github/sir-protocol-bot/scraper\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vodbaGF2kM-3"},"source":["#### Scraper"]},{"cell_type":"code","metadata":{"id":"ekYd6SDDkM-3","executionInfo":{"status":"ok","timestamp":1611003512640,"user_tz":240,"elapsed":4180,"user":{"displayName":"Vinicius Aguiar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIkJJn8xW1Jifzc3Yu1R42MS1Ter43iIMGz9IS=s64","userId":"17869074096365757693"}}},"source":["class PensadorScraper:\n","  def __init__(self):\n","    self.links = OrderedDict()\n","    self.phrases = OrderedDict()\n","    self.next_links = ['/']\n","    self.previous_links = set()\n","    self.home = 'https://www.pensador.com'\n","  \n","  def get_links(self, url, soup):\n","    links = []\n","    for a in soup.find_all('a'):\n","      try:\n","        if a['href'].startswith('/') and \\\n","           a['href'].find('.php') == -1 and \\\n","           a['href'].find('/frase') == -1 and \\\n","           a['href'].find('/colecao') == -1:\n","          links.append(a['href'])\n","      except:\n","        print('a tag without href property')\n","    links = set(links)\n","    self.links[url] = list(links)\n","    links = links - self.previous_links\n","    self.next_links.extend(links)\n","\n","  def get_phrases(self, url, soup):\n","    for card in soup.find_all('div', 'thought-card'):\n","      try:\n","        id_ = card.find('p', 'frase')['id']\n","        phrase_ = card.find('p', 'frase').text\n","        phrase_ = phrase_.strip().replace('\\u2060', '')\n","      except:\n","        continue\n","      \n","      try:\n","        author_ = card.find('span', 'autor').a.text\n","        author_url_ = card.find('span', 'autor').a['href']\n","      except:\n","        author_ = ''\n","        author_url_ = ''\n","      \n","      try:\n","        n_shares_ = card.find('div', class_='total-shares')\n","        n_shares_ = n_shares.text.replace(' compartilhamentos', '')\n","        if n_shares_[-4:] == ' mil':\n","          n_shares_ = n_shares_.replace(' mil', '')\n","          n_shares_ = float(n_shares_) * 1000\n","        elif n_shares_:\n","          n_shares_ = float(n_shares_)\n","        else:\n","          n_shares_ = 0\n","      except:\n","        n_shares_ = 0\n","        \n","      try:\n","        img_url_ = card['data-src']\n","      except:\n","        img_url_ = ''\n","      \n","      if id_ not in self.phrases:\n","        self.phrases[id_] = {\n","          'phrase': phrase_,\n","          'phrase_url': f'/frase/{id_}/',\n","          'author': author_,\n","          'author_url': author_url_,\n","          'n_shares': n_shares_,\n","          'img_url': img_url_,\n","          'urls': [url]\n","        }\n","      elif url not in self.phrases[id_]['urls']:\n","        self.phrases[id_]['urls'].append(url)\n","  \n","  def work(self):\n","    try:\n","      while self.next_links:\n","        url = self.next_links.pop()\n","        self.previous_links.add(url)\n","\n","        try:\n","          page = requests.get(self.home + url)\n","          page.raise_for_status()\n","        except requests.exceptions.HTTPError as errh:\n","          print('HTTP Error\\n', errh)\n","        except requests.exceptions.ConnectionError as errc:\n","          print('Error Connecting:\\n', errc)\n","        except requests.exceptions.Timeout as errt:\n","          print('Timeout Error:\\n', errt)\n","        except requests.exceptions.RequestException as err:\n","          print('An unexpected error:\\n', err)\n","        else:\n","          soup = BeautifulSoup(page.content, 'html.parser')\n","\n","          self.get_phrases(url, soup)\n","          self.get_links(url, soup)\n","          \n","          prev_size = len(self.previous_links)\n","          next_size = len(self.next_links)\n","          print(url, f'{prev_size}:{next_size}')\n","          clear_output(wait=True)\n","    except KeyboardInterrupt:\n","      pass\n","  \n","  def load(self):\n","    with open('./phrases.json', 'r') as file:\n","      self.phrases = json.load(file)\n","    with open('./links.json', 'r') as file:\n","      self.links = json.load(file)\n","    with open('./next_links.json', 'r') as file:\n","      self.next_links = json.load(file)\n","    with open('./previous_links.json', 'r') as file:\n","      self.previous_links = set(json.load(file))\n","  \n","  def save(self):\n","    with open('./phrases.json', 'w') as file:\n","      json.dump(self.phrases, file)\n","    with open('./links.json', 'w') as file:\n","      json.dump(self.links, file)\n","    with open('./next_links.json', 'w') as file:\n","      json.dump(self.next_links, file)\n","    with open('./previous_links.json', 'w') as file:\n","      json.dump(list(self.previous_links), file)\n","  \n","  def remove(self):\n","    Path('./phrases.json').unlink()\n","    Path('./links.json').unlink()\n","    Path('./next_links.json').unlink()\n","    Path('./previous_links.json').unlink()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"CpL_-QRJGizq","executionInfo":{"status":"ok","timestamp":1611003512640,"user_tz":240,"elapsed":4177,"user":{"displayName":"Vinicius Aguiar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIkJJn8xW1Jifzc3Yu1R42MS1Ter43iIMGz9IS=s64","userId":"17869074096365757693"}}},"source":["scraper = PensadorScraper()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YQj3CNs8kM-4","outputId":"fb29e38d-bb51-42f1-9c60-d0ed8c76081d"},"source":["scraper.work()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/mensagens_tocantes_de_agradecimento_profissional/ 571:6736\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sMcIf1GTSXr2"},"source":["scraper.save()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZPuE688x5wPs"},"source":["#### References"]},{"cell_type":"markdown","metadata":{"id":"yfZSm_3f5wPs"},"source":["[1] www.postgresqltutorial.com/\n","\n","[2] https://realpython.com/beautiful-soup-web-scraper-python/\n","\n","[3] https://devcenter.heroku.com/articles/heroku-postgresql#connecting-in-python"]}]}